#!/usr/bin/env python3
"""
æˆ¿ä»·é¢„æµ‹ - ç›¸å…³æ€§åˆ†æä»£ç 
ä¸“é—¨ç”¨äºåˆ†æç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§ï¼Œè¾…åŠ©ç‰¹å¾å·¥ç¨‹

åŠŸèƒ½ï¼š
1. è®¡ç®—ç‰¹å¾ä¸ SalePrice çš„ç›¸å…³ç³»æ•°
2. å¯è§†åŒ–ç›¸å…³æ€§ï¼ˆæ–‡æœ¬å’Œæ•°å€¼ï¼‰
3. è¯†åˆ«é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ï¼ˆå¤šé‡å…±çº¿æ€§æ£€æµ‹ï¼‰
4. æä¾›ç‰¹å¾å·¥ç¨‹å»ºè®®
5. å¯¼å‡ºç›¸å…³æ€§æŠ¥å‘Š

ç”¨æ³•:
    python src/correlation_analysis.py
    python src/correlation_analysis.py --output report.txt
    python src/correlation_analysis.py --top-n 30 --threshold 0.75
"""
from __future__ import annotations

import argparse
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd

# é¡¹ç›®è·¯å¾„
ROOT_DIR = Path(__file__).resolve().parents[1]
DATA_DIR = ROOT_DIR / "data"
TARGET_COL = 'SalePrice'


class CorrelationAnalyzer:
    """ç›¸å…³æ€§åˆ†æå™¨"""
    
    def __init__(self, train_df: pd.DataFrame, target_col: str = TARGET_COL):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            train_df: è®­ç»ƒæ•°æ®
            target_col: ç›®æ ‡å˜é‡åˆ—å
        """
        self.train_df = train_df.copy()
        self.target_col = target_col
        
        # éªŒè¯ç›®æ ‡å˜é‡å­˜åœ¨
        if target_col not in self.train_df.columns:
            raise ValueError(f"ç›®æ ‡å˜é‡ '{target_col}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        # è·å–æ•°å€¼å‹ç‰¹å¾
        self.numeric_cols = self._get_numeric_features()
        
        # å­˜å‚¨åˆ†æç»“æœ
        self.target_correlations: Dict[str, float] = {}
        self.feature_correlations: List[Tuple[str, str, float]] = []
    
    def _get_numeric_features(self) -> List[str]:
        """è·å–æ•°å€¼å‹ç‰¹å¾åˆ—è¡¨"""
        numeric_cols = self.train_df.select_dtypes(include=[np.number]).columns.tolist()
        # æ’é™¤ç›®æ ‡å˜é‡å’ŒID
        numeric_cols = [col for col in numeric_cols 
                       if col not in [self.target_col, 'Id']]
        return numeric_cols
    
    def analyze_target_correlations(self, top_n: int = 20) -> Dict[str, float]:
        """
        åˆ†æç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
        
        Args:
            top_n: è¿”å›å‰ N ä¸ªç‰¹å¾
            
        Returns:
            ç‰¹å¾ååˆ°ç›¸å…³ç³»æ•°çš„å­—å…¸ï¼ˆæŒ‰ç»å¯¹å€¼æ’åºï¼‰
        """
        print("\n" + "=" * 80)
        print("ç‰¹å¾ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§åˆ†æ")
        print("=" * 80)
        print(f"ç›®æ ‡å˜é‡: {self.target_col}")
        print(f"åˆ†æç‰¹å¾æ•°: {len(self.numeric_cols)}")
        print()
        
        # è®¡ç®—ç›¸å…³æ€§
        correlations = {}
        for col in self.numeric_cols:
            try:
                corr = self.train_df[col].corr(self.train_df[self.target_col])
                if not pd.isna(corr):
                    correlations[col] = corr
            except Exception as e:
                print(f"è­¦å‘Š: è®¡ç®— {col} çš„ç›¸å…³æ€§æ—¶å‡ºé”™: {e}")
        
        # æŒ‰ç»å¯¹å€¼æ’åº
        sorted_correlations = sorted(
            correlations.items(), 
            key=lambda x: abs(x[1]), 
            reverse=True
        )
        
        # å­˜å‚¨ç»“æœ
        self.target_correlations = dict(sorted_correlations)
        
        # è¾“å‡ºç»“æœ
        self._print_correlation_table(sorted_correlations[:top_n])
        
        return self.target_correlations
    
    def _print_correlation_table(self, correlations: List[Tuple[str, float]]):
        """æ‰“å°ç›¸å…³æ€§è¡¨æ ¼"""
        print(f"{'æ’å':<6} {'ç‰¹å¾åç§°':<30} {'ç›¸å…³ç³»æ•°':>12} {'ç›¸å…³æ€§å¼ºåº¦':<20}")
        print("-" * 75)
        
        for rank, (feature, corr) in enumerate(correlations, 1):
            strength = self._get_correlation_strength(corr)
            sign = "+" if corr >= 0 else "-"
            print(f"{rank:<6} {feature:<30} {corr:>12.4f} {strength:<20}")
        
        print()
        print(f"å…±åˆ†æäº† {len(correlations)} ä¸ªç‰¹å¾")
    
    def _get_correlation_strength(self, corr: float) -> str:
        """è·å–ç›¸å…³æ€§å¼ºåº¦æè¿°"""
        abs_corr = abs(corr)
        if abs_corr >= 0.7:
            return "å¼ºç›¸å…³ â­â­â­"
        elif abs_corr >= 0.5:
            return "ä¸­ç­‰ç›¸å…³ â­â­"
        elif abs_corr >= 0.3:
            return "å¼±ç›¸å…³ â­"
        else:
            return "å¾ˆå¼±"
    
    def analyze_feature_correlations(self, threshold: float = 0.7) -> List[Tuple[str, str, float]]:
        """
        åˆ†æç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ï¼ˆæ£€æµ‹å¤šé‡å…±çº¿æ€§ï¼‰
        
        Args:
            threshold: ç›¸å…³æ€§é˜ˆå€¼ï¼Œé«˜äºæ­¤å€¼è®¤ä¸ºé«˜åº¦ç›¸å…³
            
        Returns:
            é«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹åˆ—è¡¨ [(ç‰¹å¾1, ç‰¹å¾2, ç›¸å…³ç³»æ•°), ...]
        """
        print("\n" + "=" * 80)
        print("ç‰¹å¾ä¹‹é—´ç›¸å…³æ€§åˆ†æï¼ˆå¤šé‡å…±çº¿æ€§æ£€æµ‹ï¼‰")
        print("=" * 80)
        print(f"ç›¸å…³æ€§é˜ˆå€¼: {threshold}")
        print()
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = self.train_df[self.numeric_cols].corr()
        
        # æ‰¾å‡ºé«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹
        high_corr_pairs = []
        n_features = len(corr_matrix.columns)
        
        for i in range(n_features):
            for j in range(i + 1, n_features):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) >= threshold:
                    col1 = corr_matrix.columns[i]
                    col2 = corr_matrix.columns[j]
                    high_corr_pairs.append((col1, col2, corr_val))
        
        # æŒ‰ç›¸å…³æ€§ç»å¯¹å€¼æ’åº
        high_corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)
        
        # å­˜å‚¨ç»“æœ
        self.feature_correlations = high_corr_pairs
        
        # è¾“å‡ºç»“æœ
        if high_corr_pairs:
            print(f"å‘ç° {len(high_corr_pairs)} å¯¹é«˜åº¦ç›¸å…³çš„ç‰¹å¾ï¼ˆç›¸å…³ç³»æ•° >= {threshold}ï¼‰ï¼š")
            print()
            print(f"{'ç‰¹å¾1':<25} {'ç‰¹å¾2':<25} {'ç›¸å…³ç³»æ•°':>12} {'å»ºè®®':<20}")
            print("-" * 85)
            
            for col1, col2, corr in high_corr_pairs:
                suggestion = self._get_multicollinearity_suggestion(col1, col2)
                print(f"{col1:<25} {col2:<25} {corr:>12.4f} {suggestion:<20}")
            
            print()
            print("âš ï¸  å¤šé‡å…±çº¿æ€§å¤„ç†å»ºè®®ï¼š")
            print("   1. åˆ é™¤å…¶ä¸­ä¸€ä¸ªç‰¹å¾ï¼ˆä¿ç•™ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§æ›´é«˜çš„ï¼‰")
            print("   2. åˆ›å»ºç»„åˆç‰¹å¾ï¼ˆå¦‚ï¼šå¹³å‡å€¼ã€å·®å€¼ã€æ¯”ä¾‹ï¼‰")
            print("   3. ä½¿ç”¨ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰é™ç»´")
        else:
            print(f"âœ“ æœªå‘ç°é«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹ï¼ˆé˜ˆå€¼: {threshold}ï¼‰")
        
        return high_corr_pairs
    
    def _get_multicollinearity_suggestion(self, col1: str, col2: str) -> str:
        """è·å–å¤šé‡å…±çº¿æ€§å¤„ç†å»ºè®®"""
        # æ¯”è¾ƒä¸¤ä¸ªç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
        corr1 = abs(self.target_correlations.get(col1, 0))
        corr2 = abs(self.target_correlations.get(col2, 0))
        
        if corr1 > corr2:
            return f"ä¿ç•™ {col1}"
        elif corr2 > corr1:
            return f"ä¿ç•™ {col2}"
        else:
            return "åˆ›å»ºç»„åˆç‰¹å¾"
    
    def get_feature_engineering_suggestions(self) -> Dict[str, List[str]]:
        """
        åŸºäºç›¸å…³æ€§åˆ†ææä¾›ç‰¹å¾å·¥ç¨‹å»ºè®®
        
        Returns:
            å»ºè®®å­—å…¸ï¼Œé”®ä¸ºå»ºè®®ç±»å‹ï¼Œå€¼ä¸ºç‰¹å¾åˆ—è¡¨
        """
        print("\n" + "=" * 80)
        print("ç‰¹å¾å·¥ç¨‹å»ºè®®")
        print("=" * 80)
        
        # é«˜ç›¸å…³æ€§ç‰¹å¾ï¼ˆç›¸å…³ç³»æ•° > 0.5ï¼‰
        high_corr_features = [
            feat for feat, corr in self.target_correlations.items() 
            if abs(corr) >= 0.5
        ]
        
        suggestions = {
            'area_features': [],
            'quality_features': [],
            'time_features': [],
            'count_features': [],
            'interaction_features': []
        }
        
        # åˆ†ç±»ç‰¹å¾
        for feature in high_corr_features:
            feature_lower = feature.lower()
            
            if 'sf' in feature_lower or 'area' in feature_lower:
                suggestions['area_features'].append(feature)
            elif 'qual' in feature_lower or 'cond' in feature_lower:
                suggestions['quality_features'].append(feature)
            elif 'year' in feature_lower or 'yr' in feature_lower:
                suggestions['time_features'].append(feature)
            elif 'bath' in feature_lower or 'room' in feature_lower or 'cars' in feature_lower:
                suggestions['count_features'].append(feature)
        
        # è¾“å‡ºå»ºè®®
        self._print_suggestions(suggestions, high_corr_features)
        
        return suggestions
    
    def _print_suggestions(self, suggestions: Dict[str, List[str]], 
                          high_corr_features: List[str]):
        """æ‰“å°ç‰¹å¾å·¥ç¨‹å»ºè®®"""
        
        if suggestions['area_features']:
            print("\nğŸ“ é¢ç§¯ç›¸å…³ç‰¹å¾ï¼ˆé«˜ç›¸å…³æ€§ï¼‰:")
            print(f"   ç‰¹å¾: {', '.join(suggestions['area_features'][:5])}")
            print("   å»ºè®®ï¼š")
            print("   - åˆ›å»ºæ€»é¢ç§¯ç‰¹å¾ï¼ˆTotalSF = åœ°ä¸‹å®¤ + ä¸€æ¥¼ + äºŒæ¥¼ï¼‰")
            print("   - åˆ›å»ºé¢ç§¯æ¯”ä¾‹ç‰¹å¾ï¼ˆå¦‚ï¼šåœ°ä¸‹å®¤å æ¯” = TotalBsmtSF / TotalSFï¼‰")
            print("   - è€ƒè™‘é¢ç§¯çš„å¤šé¡¹å¼ç‰¹å¾ï¼ˆå¹³æ–¹ã€ç«‹æ–¹ã€å¹³æ–¹æ ¹ï¼‰")
            print("   - åˆ›å»ºé¢ç§¯äº¤äº’ç‰¹å¾ï¼ˆå¦‚ï¼šOverallQual Ã— GrLivAreaï¼‰")
        
        if suggestions['quality_features']:
            print("\nâ­ è´¨é‡ç›¸å…³ç‰¹å¾ï¼ˆé«˜ç›¸å…³æ€§ï¼‰:")
            print(f"   ç‰¹å¾: {', '.join(suggestions['quality_features'][:5])}")
            print("   å»ºè®®ï¼š")
            print("   - åˆ›å»ºæ€»è´¨é‡è¯„åˆ†ï¼ˆTotalQual = å„è´¨é‡ç‰¹å¾ä¹‹å’Œï¼‰")
            print("   - å°†è´¨é‡æ–‡å­—è½¬æ¢ä¸ºæ•°å€¼ï¼ˆPo=1, Fa=2, TA=3, Gd=4, Ex=5ï¼‰")
            print("   - åˆ›å»ºè´¨é‡äº¤äº’ç‰¹å¾ï¼ˆå¦‚ï¼šOverallQual Ã— GrLivAreaï¼‰")
        
        if suggestions['time_features']:
            print("\nğŸ“… æ—¶é—´ç›¸å…³ç‰¹å¾ï¼ˆé«˜ç›¸å…³æ€§ï¼‰:")
            print(f"   ç‰¹å¾: {', '.join(suggestions['time_features'])}")
            print("   å»ºè®®ï¼š")
            print("   - åˆ›å»ºæˆ¿å±‹å¹´é¾„ç‰¹å¾ï¼ˆHouseAge = YrSold - YearBuiltï¼‰")
            print("   - åˆ›å»ºæ”¹å»ºå¹´é¾„ç‰¹å¾ï¼ˆRemodAge = YrSold - YearRemodAddï¼‰")
            print("   - åˆ›å»ºè½¦åº“å¹´é¾„ç‰¹å¾ï¼ˆGarageAge = YrSold - GarageYrBltï¼‰")
        
        if suggestions['count_features']:
            print("\nğŸ”¢ æ•°é‡ç›¸å…³ç‰¹å¾ï¼ˆé«˜ç›¸å…³æ€§ï¼‰:")
            print(f"   ç‰¹å¾: {', '.join(suggestions['count_features'][:5])}")
            print("   å»ºè®®ï¼š")
            print("   - åˆ›å»ºæ€»æµ´å®¤æ•°ï¼ˆTotalBathrooms = å…¨æµ´å®¤ + 0.5Ã—åŠæµ´å®¤ï¼‰")
            print("   - åˆ›å»ºæ€»æˆ¿é—´æ•°ï¼ˆTotalRooms = å„æˆ¿é—´æ•°ä¹‹å’Œï¼‰")
            print("   - åˆ›å»ºäºŒå…ƒç‰¹å¾ï¼ˆHasGarage, HasBasement ç­‰ï¼‰")
        
        # äº¤äº’ç‰¹å¾å»ºè®®
        top_features = list(self.target_correlations.keys())[:5]
        if len(top_features) >= 2:
            print("\nğŸ”— äº¤äº’ç‰¹å¾å»ºè®®ï¼š")
            print(f"   é«˜ç›¸å…³æ€§ç‰¹å¾: {', '.join(top_features[:5])}")
            print("   å»ºè®®åˆ›å»ºäº¤äº’ç‰¹å¾ï¼š")
            for i in range(min(3, len(top_features) - 1)):
                feat1 = top_features[i]
                feat2 = top_features[i + 1]
                print(f"   - {feat1} Ã— {feat2}")
        
        print("\nğŸ’¡ é€šç”¨å»ºè®®ï¼š")
        print("   - é‡ç‚¹å…³æ³¨ç›¸å…³ç³»æ•° > 0.5 çš„ç‰¹å¾")
        print("   - å¯¹äºé«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹ï¼Œä¼˜å…ˆåˆ›å»ºç»„åˆç‰¹å¾è€Œéåˆ é™¤")
        print("   - è€ƒè™‘åˆ›å»ºæ¯”ä¾‹ç‰¹å¾ï¼ˆå¦‚ï¼šé¢ç§¯æ¯”ä¾‹ã€å¹´é¾„æ¯”ä¾‹ï¼‰")
        print("   - å¯¹åæ€åˆ†å¸ƒçš„ç‰¹å¾è¿›è¡Œ log è½¬æ¢")
    
    def generate_summary_report(self) -> str:
        """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("ç›¸å…³æ€§åˆ†ææ‘˜è¦æŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"\næ•°æ®è§„æ¨¡: {self.train_df.shape[0]} è¡Œ Ã— {self.train_df.shape[1]} åˆ—")
        report.append(f"åˆ†æç‰¹å¾æ•°: {len(self.numeric_cols)}")
        report.append(f"ç›®æ ‡å˜é‡: {self.target_col}")
        
        # é«˜ç›¸å…³æ€§ç‰¹å¾ç»Ÿè®¡
        strong_corr = sum(1 for c in self.target_correlations.values() if abs(c) >= 0.7)
        medium_corr = sum(1 for c in self.target_correlations.values() if 0.5 <= abs(c) < 0.7)
        weak_corr = sum(1 for c in self.target_correlations.values() if abs(c) < 0.5)
        
        report.append(f"\nç›¸å…³æ€§ç»Ÿè®¡ï¼š")
        report.append(f"  å¼ºç›¸å…³ï¼ˆâ‰¥0.7ï¼‰: {strong_corr} ä¸ªç‰¹å¾")
        report.append(f"  ä¸­ç­‰ç›¸å…³ï¼ˆ0.5-0.7ï¼‰: {medium_corr} ä¸ªç‰¹å¾")
        report.append(f"  å¼±ç›¸å…³ï¼ˆ<0.5ï¼‰: {weak_corr} ä¸ªç‰¹å¾")
        
        # å¤šé‡å…±çº¿æ€§ç»Ÿè®¡
        report.append(f"\nå¤šé‡å…±çº¿æ€§ï¼š")
        report.append(f"  é«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹: {len(self.feature_correlations)} å¯¹")
        
        # Top 5 ç‰¹å¾
        top_5 = list(self.target_correlations.items())[:5]
        report.append(f"\nTop 5 é‡è¦ç‰¹å¾ï¼š")
        for i, (feat, corr) in enumerate(top_5, 1):
            report.append(f"  {i}. {feat}: {corr:.4f}")
        
        return "\n".join(report)
    
    def save_report(self, output_path: Path):
        """ä¿å­˜å®Œæ•´æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        with open(output_path, 'w', encoding='utf-8') as f:
            # é‡å®šå‘è¾“å‡º
            original_stdout = sys.stdout
            sys.stdout = f
            
            try:
                print("=" * 80)
                print("House Prices ç›¸å…³æ€§åˆ†æå®Œæ•´æŠ¥å‘Š")
                print("=" * 80)
                print(f"\nç”Ÿæˆæ—¶é—´: {pd.Timestamp.now()}")
                print(f"æ•°æ®è§„æ¨¡: {self.train_df.shape[0]} è¡Œ Ã— {self.train_df.shape[1]} åˆ—")
                print()
                
                # è¿è¡Œæ‰€æœ‰åˆ†æ
                self.analyze_target_correlations(top_n=50)
                self.analyze_feature_correlations(threshold=0.7)
                self.get_feature_engineering_suggestions()
                
                print("\n" + self.generate_summary_report())
                
            finally:
                sys.stdout = original_stdout
        
        print(f"\nâœ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")


def load_data(data_path: Path) -> pd.DataFrame:
    """åŠ è½½æ•°æ®"""
    if not data_path.exists():
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    
    df = pd.read_csv(data_path)
    print(f"âœ“ æˆåŠŸåŠ è½½æ•°æ®: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
    return df


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æˆ¿ä»·é¢„æµ‹ç›¸å…³æ€§åˆ†æ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨
  python src/correlation_analysis.py
  
  # æ˜¾ç¤ºæ›´å¤šç‰¹å¾
  python src/correlation_analysis.py --top-n 30
  
  # ä¿å­˜æŠ¥å‘Š
  python src/correlation_analysis.py --output report.txt
  
  # è‡ªå®šä¹‰é˜ˆå€¼
  python src/correlation_analysis.py --threshold 0.8
        """
    )
    
    parser.add_argument(
        '--data',
        type=str,
        default=str(DATA_DIR / 'train.csv'),
        help='è®­ç»ƒæ•°æ®è·¯å¾„ï¼ˆé»˜è®¤: data/train.csvï¼‰'
    )
    parser.add_argument(
        '--output',
        type=str,
        default=None,
        help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰'
    )
    parser.add_argument(
        '--top-n',
        type=int,
        default=20,
        help='æ˜¾ç¤ºå‰ N ä¸ªç›¸å…³æ€§æœ€é«˜çš„ç‰¹å¾ï¼ˆé»˜è®¤: 20ï¼‰'
    )
    parser.add_argument(
        '--threshold',
        type=float,
        default=0.7,
        help='ç‰¹å¾é—´ç›¸å…³æ€§é˜ˆå€¼ï¼ˆé»˜è®¤: 0.7ï¼‰'
    )
    parser.add_argument(
        '--target',
        type=str,
        default=TARGET_COL,
        help=f'ç›®æ ‡å˜é‡åˆ—åï¼ˆé»˜è®¤: {TARGET_COL}ï¼‰'
    )
    
    args = parser.parse_args()
    
    try:
        # åŠ è½½æ•°æ®
        train_df = load_data(Path(args.data))
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = CorrelationAnalyzer(train_df, target_col=args.target)
        
        # è¿è¡Œåˆ†æ
        analyzer.analyze_target_correlations(top_n=args.top_n)
        analyzer.analyze_feature_correlations(threshold=args.threshold)
        analyzer.get_feature_engineering_suggestions()
        
        # ä¿å­˜æŠ¥å‘Šï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.output:
            output_path = Path(args.output)
            analyzer.save_report(output_path)
        
        # æ‰“å°æ‘˜è¦
        print("\n" + analyzer.generate_summary_report())
        
        print("\n" + "=" * 80)
        print("åˆ†æå®Œæˆï¼")
        print("=" * 80)
        
    except Exception as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()


